{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started with Spacy\n",
    "\n",
    "Installation instructions\n",
    "\n",
    "```\n",
    "pip install spacy\n",
    "python -m spacy download en\n",
    "pip install nltk\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.7-cp39-cp39-macosx_11_0_arm64.whl (6.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.3 MB 749 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 9.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests<3.0.0,>=2.13.0\n",
      "  Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "\u001b[K     |████████████████████████████████| 64 kB 5.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.5.1-cp39-cp39-macosx_11_0_arm64.whl (635 kB)\n",
      "\u001b[K     |████████████████████████████████| 635 kB 7.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting thinc<8.4.0,>=8.3.4\n",
      "  Downloading thinc-8.3.6-cp39-cp39-macosx_11_0_arm64.whl (848 kB)\n",
      "\u001b[K     |████████████████████████████████| 848 kB 11.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.13-cp39-cp39-macosx_11_0_arm64.whl (26 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.10-cp39-cp39-macosx_11_0_arm64.whl (129 kB)\n",
      "\u001b[K     |████████████████████████████████| 129 kB 14.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.11-cp39-cp39-macosx_11_0_arm64.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 4.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/admin/Desktop/MDS/venv/lib/python3.9/site-packages (from spacy) (58.0.4)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 8.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting typer<1.0.0,>=0.3.0\n",
      "  Downloading typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 12.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm<5.0.0,>=4.38.0\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Collecting numpy>=1.19.0\n",
      "  Using cached numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl (5.3 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/admin/Desktop/MDS/venv/lib/python3.9/site-packages (from spacy) (25.0)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "\u001b[K     |████████████████████████████████| 182 kB 6.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "\u001b[K     |████████████████████████████████| 444 kB 11.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting jinja2\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "\u001b[K     |████████████████████████████████| 134 kB 13.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "\u001b[K     |████████████████████████████████| 307 kB 9.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting click\n",
      "  Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2025.7.34-cp39-cp39-macosx_11_0_arm64.whl (285 kB)\n",
      "\u001b[K     |████████████████████████████████| 285 kB 11.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting language-data>=1.2\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.4 MB 10.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting marisa-trie>=1.1.0\n",
      "  Downloading marisa_trie-1.3.0-cp39-cp39-macosx_11_0_arm64.whl (157 kB)\n",
      "\u001b[K     |████████████████████████████████| 157 kB 10.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting annotated-types>=0.6.0\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.33.2\n",
      "  Downloading pydantic_core-2.33.2-cp39-cp39-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 9.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.12.2 in /Users/admin/Desktop/MDS/venv/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.1)\n",
      "Collecting typing-inspection>=0.4.0\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Collecting charset_normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.3-cp39-cp39-macosx_10_9_universal2.whl (207 kB)\n",
      "\u001b[K     |████████████████████████████████| 207 kB 14.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "\u001b[K     |████████████████████████████████| 129 kB 11.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "\u001b[K     |████████████████████████████████| 161 kB 5.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting blis<1.4.0,>=1.3.0\n",
      "  Using cached blis-1.3.0-cp39-cp39-macosx_10_9_universal2.whl\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Collecting shellingham>=1.3.0\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting rich>=10.11.0\n",
      "  Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "\u001b[K     |████████████████████████████████| 243 kB 10.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/admin/Desktop/MDS/venv/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1\n",
      "  Downloading smart_open-7.3.0.post1-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 2.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting cloudpathlib<1.0.0,>=0.7.0\n",
      "  Downloading cloudpathlib-0.21.1-py3-none-any.whl (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 4.2 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting wrapt\n",
      "  Downloading wrapt-1.17.3-cp39-cp39-macosx_11_0_arm64.whl (38 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-3.0.2-cp39-cp39-macosx_11_0_arm64.whl (12 kB)\n",
      "Installing collected packages: mdurl, typing-inspection, pydantic-core, markdown-it-py, catalogue, annotated-types, wrapt, urllib3, srsly, shellingham, rich, pydantic, numpy, murmurhash, marisa-trie, idna, cymem, click, charset-normalizer, certifi, wasabi, typer, smart-open, requests, preshed, MarkupSafe, language-data, confection, cloudpathlib, blis, weasel, tqdm, thinc, spacy-loggers, spacy-legacy, regex, langcodes, joblib, jinja2, spacy, nltk\n",
      "Successfully installed MarkupSafe-3.0.2 annotated-types-0.7.0 blis-1.3.0 catalogue-2.0.10 certifi-2025.8.3 charset-normalizer-3.4.3 click-8.1.8 cloudpathlib-0.21.1 confection-0.1.5 cymem-2.0.11 idna-3.10 jinja2-3.1.6 joblib-1.5.1 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.3.0 markdown-it-py-3.0.0 mdurl-0.1.2 murmurhash-1.0.13 nltk-3.9.1 numpy-2.0.2 preshed-3.0.10 pydantic-2.11.7 pydantic-core-2.33.2 regex-2025.7.34 requests-2.32.4 rich-14.1.0 shellingham-1.5.4 smart-open-7.3.0.post1 spacy-3.8.7 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.6 tqdm-4.67.1 typer-0.16.0 typing-inspection-0.4.1 urllib3-2.5.0 wasabi-1.1.3 weasel-0.4.1 wrapt-1.17.3\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/Users/admin/Desktop/MDS/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/admin/Desktop/MDS/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
      "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0ma \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m02\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/Desktop/MDS/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization: Sentence & Word Tokenization In Spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"British Airways will drop its flights to Beijing from October. It feels the impact of being banned from Russian airspace.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "British Airways will drop its flights to Beijing from October.\n",
      "It feels the impact of being banned from Russian airspace.\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "British\n",
      "Airways\n",
      "will\n",
      "drop\n",
      "its\n",
      "flights\n",
      "to\n",
      "Beijing\n",
      "from\n",
      "October\n",
      ".\n",
      "It\n",
      "feels\n",
      "the\n",
      "impact\n",
      "of\n",
      "being\n",
      "banned\n",
      "from\n",
      "Russian\n",
      "airspace\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "    for word in sentence:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "https://spacy.io/usage/processing-pipelines#pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x12308f1c0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x12308fc40>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x122eff9e0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x1230eef00>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x123133240>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x122eff890>)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build blank pipeline and add new at run time\n",
    "source_nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ner']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nlp.add_pipe(\"ner\", source=source_nlp)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captain  |   None  |  \n",
      "america  |   None  |  \n",
      "ate  |   None  |  \n",
      "100  |   None  |  \n",
      "$  |   None  |  \n",
      "of  |   None  |  \n",
      "Burger  |   None  |  \n",
      ".  |   None  |  \n",
      "Then  |   None  |  \n",
      "he  |   None  |  \n",
      "said  |   None  |  \n",
      "I  |   None  |  \n",
      "can  |   None  |  \n",
      "do  |   None  |  \n",
      "this  |   None  |  \n",
      "all  |   None  |  \n",
      "day  |   None  |  \n",
      ".  |   None  |  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/Desktop/MDS/venv/lib/python3.9/site-packages/spacy/glossary.py:20: UserWarning: [W118] Term '' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Captain america ate 100$ of Burger. Then he said I can do this all day.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, \" | \", token.pos_, spacy.explain(token.pos_), \" | \", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elon  |  PROPN  |  proper noun  |  NNP  |  noun, proper singular\n",
      "flew  |  VERB  |  verb  |  VBD  |  verb, past tense\n",
      "to  |  ADP  |  adposition  |  IN  |  conjunction, subordinating or preposition\n",
      "mars  |  NOUN  |  noun  |  NNS  |  noun, plural\n",
      "yesterday  |  NOUN  |  noun  |  NN  |  noun, singular or mass\n",
      ".  |  PUNCT  |  punctuation  |  .  |  punctuation mark, sentence closer\n",
      "He  |  PRON  |  pronoun  |  PRP  |  pronoun, personal\n",
      "carried  |  VERB  |  verb  |  VBD  |  verb, past tense\n",
      "biryani  |  ADJ  |  adjective  |  JJ  |  adjective (English), other noun-modifier (Chinese)\n",
      "masala  |  NOUN  |  noun  |  NN  |  noun, singular or mass\n",
      "with  |  ADP  |  adposition  |  IN  |  conjunction, subordinating or preposition\n",
      "him  |  PRON  |  pronoun  |  PRP  |  pronoun, personal\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Elon flew to mars yesterday. He carried biryani masala with him\")\n",
    "\n",
    "for token in doc:\n",
    "    # print(token,\" | \", token.pos_, \" | \", spacy.explain(token.pos_))\n",
    "    print(token,\" | \", token.pos_, \" | \", \n",
    "          spacy.explain(token.pos_), \" | \", token.tag_, \" | \",\n",
    "            spacy.explain(token.tag_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/admin/Desktop/MDS/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "Collecting en-core-web-lg==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m  \u001b[33m0:01:01\u001b[0m[0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x126076d00>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Donad Trump was President of USA"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"Donad Trump was President of USA\")\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Donad Trump,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thursday | DATE | Absolute or relative dates or periods\n",
      "Chaudhari | ORG | Companies, agencies, institutions, etc.\n",
      "a week | DATE | Absolute or relative dates or periods\n",
      "Kamala Harris | PERSON | People, including fictional\n",
      "Tim Walz | PERSON | People, including fictional\n",
      "millions of dollars | MONEY | Monetary values, including unit\n",
      "Trump | ORG | Companies, agencies, institutions, etc.\n",
      "Trump | ORG | Companies, agencies, institutions, etc.\n",
      "one | CARDINAL | Numerals that do not fall under another type\n",
      "Donald Trump | PERSON | People, including fictional\n",
      "Trump | PERSON | People, including fictional\n",
      "Harris | PERSON | People, including fictional\n",
      "10 September | DATE | Absolute or relative dates or periods\n",
      "ABC News | ORG | Companies, agencies, institutions, etc.\n",
      "Ms Harris | PERSON | People, including fictional\n",
      "Trump | PERSON | People, including fictional\n",
      "two | CARDINAL | Numerals that do not fall under another type\n",
      "Harris | PERSON | People, including fictional\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"\"\"\n",
    "          On Thursday, Ramesh Chaudhari walked into a room of journalists gathered at his Mar-a-Lago estate for a news conference. He didn’t look particularly happy.\n",
    "\n",
    "His remarks came after a week in which Kamala Harris and her new running mate Tim Walz have dominated media attention, raked in millions of dollars and enjoyed a bump in polling. Trump’s media event seemed more an attempt to win back the spotlight than announce anything new.\n",
    "\n",
    "Just before Trump stepped up to the podium, one of his advisors texted me the wry assessment that Donald Trump is “never boring!!” (the exclamation marks were his).\n",
    "\n",
    "The event included a couple of news items. Mr Trump announced that he’d agreed to join a TV debate with Vice President Harris on 10 September. ABC News, the debate host, confirmed that Ms Harris had agreed to participate as well. Trump also said he’d like to do two more debates. There’s no word from the Harris team yet on whether they’ve accepted those additional matchups.\n",
    "          \"\"\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \"|\", ent.label_, \"|\", spacy.explain(ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla Inc  |  ORG  |  0 | 9\n",
      "Twitter Inc  |  PERSON  |  30 | 41\n",
      "$45 billion  |  MONEY  |  46 | 57\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Tesla Inc is going to acquire Twitter Inc for $45 billion\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \" | \", ent.label_, \" | \", ent.start_char, \"|\", ent.end_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tesla Inc\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is going to acquire \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Twitter Inc\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $45 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
